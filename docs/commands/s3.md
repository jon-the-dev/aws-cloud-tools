# S3 Commands

AWS S3 bucket and object management commands for comprehensive S3 operations.

## Commands

### `list-buckets`

List S3 buckets with details including region and optional size information.

```bash
aws-cloud-utilities s3 list-buckets
```

**Options:**
- `--region REGION` - Filter buckets by region (default: show all regions)
- `--all-regions` - Show buckets from all regions (default behavior)
- `--include-size` - Include bucket size information from CloudWatch metrics
- `--output-file FILE` - Output file for bucket list (supports .json, .yaml, .csv)

**Examples:**
```bash
# List all buckets
aws-cloud-utilities s3 list-buckets

# List buckets in specific region
aws-cloud-utilities s3 list-buckets --region us-east-1

# Include size information
aws-cloud-utilities s3 list-buckets --include-size

# Save to file
aws-cloud-utilities s3 list-buckets --output-file buckets.json
```

### `create-bucket`

Create a new S3 bucket with optional configuration.

```bash
aws-cloud-utilities s3 create-bucket BUCKET_NAME
```

**Arguments:**
- `BUCKET_NAME` - Name of the bucket to create

**Options:**
- `--region REGION` - AWS region for the bucket (default: current region or us-west-2)
- `--versioning` - Enable versioning on the bucket
- `--encryption` - Enable default encryption on the bucket
- `--public-access-block` - Enable public access block (default: enabled)

**Examples:**
```bash
# Create basic bucket
aws-cloud-utilities s3 create-bucket my-new-bucket

# Create bucket with versioning and encryption
aws-cloud-utilities s3 create-bucket my-secure-bucket --versioning --encryption

# Create bucket in specific region
aws-cloud-utilities s3 create-bucket my-regional-bucket --region us-west-2
```

### `download`

Download objects from S3 bucket with various filtering options.

```bash
aws-cloud-utilities s3 download BUCKET_NAME
```

**Arguments:**
- `BUCKET_NAME` - Name of the S3 bucket

**Options:**
- `--prefix PREFIX` - Object prefix to filter downloads
- `--local-dir DIR` - Local directory to download to (default: current directory)
- `--max-objects NUM` - Maximum number of objects to download
- `--dry-run` - Show what would be downloaded without actually downloading
- `--include-pattern PATTERN` - Include objects matching pattern
- `--exclude-pattern PATTERN` - Exclude objects matching pattern

**Examples:**
```bash
# Download all objects
aws-cloud-utilities s3 download my-bucket

# Download with prefix filter
aws-cloud-utilities s3 download my-bucket --prefix logs/2024/

# Download to specific directory
aws-cloud-utilities s3 download my-bucket --local-dir ./downloads

# Dry run to see what would be downloaded
aws-cloud-utilities s3 download my-bucket --dry-run
```

### `nuke-bucket`

Completely delete a bucket and all its contents (use with extreme caution).

```bash
aws-cloud-utilities s3 nuke-bucket BUCKET_NAME
```

**Arguments:**
- `BUCKET_NAME` - Name of the bucket to delete

**Options:**
- `--force` - Skip confirmation prompt
- `--delete-versions` - Delete all object versions (required for versioned buckets)

**Examples:**
```bash
# Delete bucket (with confirmation)
aws-cloud-utilities s3 nuke-bucket my-old-bucket

# Force delete without confirmation
aws-cloud-utilities s3 nuke-bucket my-old-bucket --force

# Delete versioned bucket
aws-cloud-utilities s3 nuke-bucket my-versioned-bucket --delete-versions --force
```

### `bucket-details`

Get comprehensive details about an S3 bucket.

```bash
aws-cloud-utilities s3 bucket-details BUCKET_NAME
```

**Arguments:**
- `BUCKET_NAME` - Name of the bucket to analyze

**Options:**
- `--include-objects` - Include object listing in details
- `--max-objects NUM` - Maximum number of objects to list (default: 1000)
- `--output-file FILE` - Save results to file

**Features:**
- Bucket configuration and policies
- Versioning and lifecycle settings
- Encryption and access control
- Object statistics and samples

**Examples:**
```bash
# Get bucket details
aws-cloud-utilities s3 bucket-details my-bucket

# Include object listing
aws-cloud-utilities s3 bucket-details my-bucket --include-objects

# Save to file
aws-cloud-utilities s3 bucket-details my-bucket --output-file bucket-analysis.json
```

### `delete-versions`

Delete specific object versions from a versioned bucket.

```bash
aws-cloud-utilities s3 delete-versions BUCKET_NAME
```

**Arguments:**
- `BUCKET_NAME` - Name of the versioned bucket

**Options:**
- `--prefix PREFIX` - Object prefix to filter deletions
- `--older-than DAYS` - Delete versions older than specified days
- `--keep-latest NUM` - Keep the latest N versions of each object
- `--dry-run` - Show what would be deleted without actually deleting

**Examples:**
```bash
# Delete old versions (dry run)
aws-cloud-utilities s3 delete-versions my-bucket --older-than 30 --dry-run

# Keep only latest 5 versions
aws-cloud-utilities s3 delete-versions my-bucket --keep-latest 5

# Delete versions with prefix
aws-cloud-utilities s3 delete-versions my-bucket --prefix logs/ --older-than 7
```

### `restore-objects`

Restore objects from Glacier or Deep Archive storage classes.

```bash
aws-cloud-utilities s3 restore-objects BUCKET_NAME
```

**Arguments:**
- `BUCKET_NAME` - Name of the bucket containing archived objects

**Options:**
- `--prefix PREFIX` - Object prefix to filter restorations
- `--days DAYS` - Number of days to keep restored objects available (default: 1)
- `--tier TIER` - Restoration tier (Standard, Bulk, Expedited) [default: Standard]
- `--dry-run` - Show what would be restored without actually restoring

**Examples:**
```bash
# Restore objects with prefix
aws-cloud-utilities s3 restore-objects my-bucket --prefix archive/2023/

# Expedited restoration for 7 days
aws-cloud-utilities s3 restore-objects my-bucket --tier Expedited --days 7

# Dry run to see what would be restored
aws-cloud-utilities s3 restore-objects my-bucket --dry-run
```

### `analyze-encryption`

Analyze S3 bucket encryption configurations with parallel processing and generate comprehensive HTML reports.

```bash
aws-cloud-utilities s3 analyze-encryption
```

**Features:**
- üöÄ **High-Performance Parallel Processing**: Analyzes buckets concurrently using ThreadPoolExecutor (5-10x faster than sequential processing)
- üîí **Encryption Categorization**: Clear separation between SSE-S3 (AES256) and SSE-KMS encrypted buckets
- üîë **KMS Key Details**: View which KMS keys are being used for each bucket
- ‚ö†Ô∏è **Unencrypted Bucket Detection**: Identify buckets without default encryption
- üìä **HTML Report Generation**: Creates beautiful, responsive HTML reports with statistics and details
- üìÑ **JSON Export**: Also saves data in JSON format for programmatic access

**Options:**
- `--region REGION` - Filter buckets by region (default: analyze all regions)
- `--output-file FILE` - Output HTML file for encryption analysis report (default: s3_encryption_report_<timestamp>.html)
- `--workers NUM` - Number of parallel workers for bucket analysis (default: from config)
- `--tag-key KEY` - Filter S3 buckets by tag key (e.g., Environment)
- `--tag-value VALUE` - Filter S3 buckets by tag value (requires --tag-key)

**Report Contents:**
- Summary statistics with encryption percentages
- SSE-KMS encrypted buckets with KMS key details
- SSE-S3 (AES256) encrypted buckets
- Unencrypted buckets requiring attention
- Error details for buckets with access issues

**Examples:**
```bash
# Analyze all buckets across all regions
aws-cloud-utilities s3 analyze-encryption

# Analyze buckets in specific region
aws-cloud-utilities s3 analyze-encryption --region us-east-1

# Custom output file and parallel workers
aws-cloud-utilities s3 analyze-encryption --output-file my-encryption-report.html --workers 20

# Filter by tags
aws-cloud-utilities s3 analyze-encryption --tag-key Environment --tag-value Production

# Analyze with high parallelism for large accounts
aws-cloud-utilities s3 analyze-encryption --workers 50
```

**Performance:**
The encryption analysis uses parallel processing to analyze multiple buckets simultaneously:
- Default workers: 4 (configurable via `--workers`)
- With 10 workers: Can analyze 100 buckets in ~10 seconds
- With 20 workers: Can analyze 1000 buckets in ~2 minutes

**Output Files:**
- `s3_encryption_report_<timestamp>.html` - Beautiful HTML report you can open in a browser
- `s3_encryption_report_<timestamp>.json` - JSON data for programmatic access

## Global Options

All S3 commands support these global options:

- `--profile PROFILE` - AWS profile to use
- `--region REGION` - AWS region
- `--output FORMAT` - Output format (table, json, yaml, csv)
- `--verbose` - Enable verbose output
- `--debug` - Enable debug mode

## Examples

### Bucket Management Workflow

```bash
#!/bin/bash
# Complete bucket management workflow

echo "=== Current Buckets ==="
aws-cloud-utilities s3 list-buckets --include-size

echo "=== Creating New Bucket ==="
aws-cloud-utilities s3 create-bucket my-new-project-bucket --versioning --encryption

echo "=== Bucket Details ==="
aws-cloud-utilities s3 bucket-details my-new-project-bucket --output-file bucket-config.json
```

### Data Migration Script

```bash
#!/bin/bash
# Download and backup bucket contents

BUCKET_NAME="my-source-bucket"
BACKUP_DIR="./backup-$(date +%Y%m%d)"

echo "=== Analyzing Bucket ==="
aws-cloud-utilities s3 bucket-details $BUCKET_NAME --include-objects

echo "=== Downloading Contents ==="
aws-cloud-utilities s3 download $BUCKET_NAME --local-dir $BACKUP_DIR

echo "=== Backup Complete ==="
echo "Backup saved to: $BACKUP_DIR"
```

### Cleanup and Maintenance

```bash
#!/bin/bash
# Bucket cleanup and maintenance

BUCKET_NAME="my-versioned-bucket"

echo "=== Current Bucket Status ==="
aws-cloud-utilities s3 bucket-details $BUCKET_NAME

echo "=== Cleaning Old Versions (Dry Run) ==="
aws-cloud-utilities s3 delete-versions $BUCKET_NAME --older-than 90 --dry-run

echo "=== Restoring Archived Objects ==="
aws-cloud-utilities s3 restore-objects $BUCKET_NAME --prefix important/ --days 3
```

## Common Use Cases

1. **Bucket Discovery and Analysis**
   ```bash
   aws-cloud-utilities s3 list-buckets --include-size
   aws-cloud-utilities s3 bucket-details my-bucket --include-objects
   ```

2. **Security and Encryption Analysis**
   ```bash
   # Generate comprehensive encryption report
   aws-cloud-utilities s3 analyze-encryption

   # Analyze production buckets only
   aws-cloud-utilities s3 analyze-encryption --tag-key Environment --tag-value Production

   # High-performance analysis with 20 parallel workers
   aws-cloud-utilities s3 analyze-encryption --workers 20 --output-file security-audit.html
   ```

3. **Data Download and Backup**
   ```bash
   aws-cloud-utilities s3 download my-bucket --local-dir ./backup
   aws-cloud-utilities s3 download my-bucket --prefix logs/2024/ --max-objects 1000
   ```

4. **Bucket Lifecycle Management**
   ```bash
   aws-cloud-utilities s3 delete-versions my-bucket --older-than 30 --keep-latest 5
   aws-cloud-utilities s3 restore-objects my-bucket --prefix archive/
   ```

5. **Bucket Creation and Setup**
   ```bash
   aws-cloud-utilities s3 create-bucket my-new-bucket --versioning --encryption
   aws-cloud-utilities s3 bucket-details my-new-bucket
   ```

## Security Considerations

- Always use `--dry-run` before destructive operations
- The `nuke-bucket` command permanently deletes all data
- Restored objects from Glacier incur additional costs
- Consider using `--force` flag carefully in automated scripts
